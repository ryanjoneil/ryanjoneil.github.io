<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title>adventures in optimization</title>
    <link href="http://ryanjoneil.github.io/rss.xml" rel="self"/>
    <link href="http://ryanjoneil.github.io"/>
    <id>http://ryanjoneil.github.io</id>
    
    
    <updated>2015-09-27T00:00:00></updated>
    <author>
      <name>Ryan J. O'Neil</name>
      <email>ryanjoneil@gmail.com</email>
    </author>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

  
  <entry>
    <title type="text">Polygon Intersections Part 1 - Detecting Overlap</title>
    <link href="http://ryanjoneil.github.io/posts/2015-09-27-polygon-intersections-part-1-detecting-overlap.html"/>
    <updated>2015-09-27T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2015-09-27-polygon-intersections-part-1-detecting-overlap.html</id>
    <description>Detecting when two polygons touch or overlap.</description>
    <content type="html"><![CDATA[

<p>A fun geometry problem to think about is: given two polygons, do they intersect? That is, do they touch on the border or overlap? Does one reside entirely within the other? While this question has obvious applications in computer graphics <em>(see: arcade games of the 1980s)</em>, it's also important in areas such as <a href="http://paginas.fe.up.pt/~esicup/tiki-index.php">cutting &amp; packing problems</a>.</p>

<p>There are a number of way to answer this. In computer graphics, the problem is often approached using a <a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)">clipping algorithm</a>. This post examines a couple of simpler techniques using linear inequalities and properties of convexity. To simplify the presentation, we assume we ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Are We Getting Happier?</title>
    <link href="http://ryanjoneil.github.io/posts/2014-07-18-are-we-getting-happier.html"/>
    <updated>2014-07-18T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2014-07-18-are-we-getting-happier.html</id>
    <description>A look at trends in Hedonometer.org&#39;s happiness data using Julia, JuMP, and GLPK.</description>
    <content type="html"><![CDATA[

<h4>Introduction</h4>

<p><a href="http://www.hedonometer.org/">Hedonometer.org</a> popped onto my radar a couple weeks ago. It's a nifty project, attempting to convert samples of words found in the Twitter Gardenhose feed into a time series of happiness.</p>

<p>While I'm not a computational social scientist, I must say the data does have a nice intuitive quality to it. There are obvious trends in happiness associated with major holidays, days of the week, and seasons. It seems like the sort of data that could be decomposed into trends based on those various components. The Hedonometer group has, of course, done extensive analyses of their ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Preprocessing for Routing Problems - Part 2</title>
    <link href="http://ryanjoneil.github.io/posts/2014-06-27-preprocessing-for-routing-problems-part-2.html"/>
    <updated>2014-06-27T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2014-06-27-preprocessing-for-routing-problems-part-2.html</id>
    <description>Preprocessing techniques for dividing space based on closest points by driving distance.</description>
    <content type="html"><![CDATA[

<p>In the <a href="2014-05-28-preprocessing-for-routing-problems-part-1.html">previous post</a>, we considered preprocessing for the vehicle routing problem where the vehicles have different starting locations. Our goal was to create potentially overlapping regions for the entire US which we could later use for route construction. We defined these regions using all 5-digit zip codes in the continental US for which one of our regional headquarters is the closest, or one of $n$ closest, headquarters in terms of Euclidean distance. The resulting regions gave us some flexibility in terms of how much redundancy we allow in our coverage of the country.</p>

<p>This post refines those regions, replacing ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Preprocessing for Routing Problems - Part 1</title>
    <link href="http://ryanjoneil.github.io/posts/2014-05-28-preprocessing-for-routing-problems-part-1.html"/>
    <updated>2014-05-28T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2014-05-28-preprocessing-for-routing-problems-part-1.html</id>
    <description>Preprocessing techniques for splitting space into regions which are closest to a set of points.</description>
    <content type="html"><![CDATA[

<p>Consider an instance of the
<a href="http://en.wikipedia.org/wiki/Vehicle_routing_problem">vehicle routing problem</a>
in which we have drivers that are geographically distributed, each in a unique
location. Our goal is to deliver goods or services to a set of destinations at
the lowest cost. It does not matter to our customers which driver goes to which
destination, so long as the deliveries are made.</p>

<p>One can think of this problem as a collection of
<a href="http://en.wikipedia.org/wiki/Travelling_salesman_problem">travelling salesman problems</a>,
where there are multiple salespeople in different locations and a shared set of destinations.
We attempt to find the minimum cost schedule for all salespeople that visits all ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Capturing stdout in a Python Child Process</title>
    <link href="http://ryanjoneil.github.io/posts/2014-02-14-capturing-stdout-in-a-python-child-process.html"/>
    <updated>2014-02-14T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2014-02-14-capturing-stdout-in-a-python-child-process.html</id>
    <description>How to capture standard output when running a child process in Python.</description>
    <content type="html"><![CDATA[

<p>Lately at work I've been putting together a web management console that handles execution of some of our
long running Gurobi models. This makes a lot of sense to do since the models run on Gurobi Cloud for hours
or even days before achieving their desired optimality gaps. Gurobi Cloud requires a persistent connection,
so we use a server to handle that instead of solving models from our desktop machines. In a sense, this is
a bit of a throwback to the time sharing systems from before the PC era.</p>

<p>As a result, I've had to update my ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Chebyshev Centers of Polygons with gurobipy</title>
    <link href="http://ryanjoneil.github.io/posts/2014-02-03-chebyshev-centers-of-polygons-with-gurobipy.html"/>
    <updated>2014-02-03T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2014-02-03-chebyshev-centers-of-polygons-with-gurobipy.html</id>
    <description>Finding the maximum area inscribed circle inside a polygon.</description>
    <content type="html"><![CDATA[

<p>A common problem in handling geometric data is determining the center of a given polygon. This is not quite so easy as it sounds as there is not a single definition of center that makes sense in all cases. For instance, sometimes computing the center of a polygon's bounding box may be sufficient. In some instances this may give a point on an edge (consider a right triangle). If the given polygon is non-convex, that point may not even be inside or on its boundary.</p>

<p>This post looks at computing Chebyshev centers for arbitrary convex polygons. We employ <a href="http://cvxopt.org/examples/book/centers.html">essentially ...</a></p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Network Splitting</title>
    <link href="http://ryanjoneil.github.io/posts/2013-07-29-network-splitting.html"/>
    <updated>2013-07-29T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2013-07-29-network-splitting.html</id>
    <description>Splitting large networks into fully connected subnetworks. Also, Las Vegas!</description>
    <content type="html"><![CDATA[

<p><i>Note: A reader pointed out that Union-Find is a very efficient way to accomplish this task. So if you need to do something similar, start there!</i></p>

<p>Last week, Paul Rubin wrote an excellent post on <a href="http://orinanobworld.blogspot.com/2013/07/extracting-connected-graph.html">Extracting a Connected Graph</a> from an existing graph. Lately I've been performing related functions on data from <a href="http://www.openstreetmap.org/">OpenStreetMap</a>, though without access to a solver. In my case I'm taking in arbitrary network data and splitting it into disconnected subnetworks. I thought it might be a good case study to show an algorithmic way doing this and  some of the performance issues I ran ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Lagrangian Relaxation with gurobipy</title>
    <link href="http://ryanjoneil.github.io/posts/2012-09-22-langrangian-relaxation-with-gurobipy.html"/>
    <updated>2012-09-22T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2012-09-22-langrangian-relaxation-with-gurobipy.html</id>
    <description>Solving integer programs with Lagrangian relaxation and Gurobi.</description>
    <content type="html"><![CDATA[

<p><i>Note: this is still a new technique to me, so please point out any errors and I will correct them in the post.</i></p>
<p><i>Correction: $b_{ij}$ is now $b_j$ in the second set of constraints.</i></p>

<p>We've been studying Lagrangian Relaxation (LR) in <a href="http://seor.gmu.edu/syllabi/12F/OR782.pdf">the combinatorial optimization course I'm taking this term</a>, and I had some difficulty finding a simple example covering its application. In case anyone else finds it useful, I'm posting a Python version for solving the <a href="http://en.wikipedia.org/wiki/Generalized_assignment_problem">Generalized Assignment Problem</a> (GAP). This won't discuss the theory of LR at all, just give example code using Gurobi ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">A Few Thoughts On Music and Computer Programming</title>
    <link href="http://ryanjoneil.github.io/posts/2012-03-26-a-few-thoughts-on-music-and-computer-programming.html"/>
    <updated>2012-03-26T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2012-03-26-a-few-thoughts-on-music-and-computer-programming.html</id>
    <description>Thinking concurrently and parallel notation systems.</description>
    <content type="html"><![CDATA[

<p>Greg Linch started <a href="http://www.greglinch.com/2012/03/music-and-code-great-insights-from-david-johnson-zed-shaw-and-others.html">a discussion</a> recently on Twitter regarding music and coding.  The apex of the conversation was Zed Shaw pointing to his own well-stated <a href="http://www.reddit.com/r/Guitar/comments/rd4fl/my_friends_mom_is_a_bit_of_a_douche/c44x1bg">comments on the matter</a>.</p>

<p>I got back just over a couple hours ago from a weekly rehearsal, so I've got a number of things I'd like to mention swimming around in my head.  Here are a few:</p>

<ol>
<li>To "Linguistic Skills" I'd add that musical notation is specifically built to enable certain domain-specific elements.  Its staved nature allows a high degree of parallelism.  I can't think of any other common language that ...</li></ol>]]></content>
  </entry>
  
  <entry>
    <title type="text">Normal Magic Squares</title>
    <link href="http://ryanjoneil.github.io/posts/2012-01-13-normal-magic-squares.html"/>
    <updated>2012-01-13T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2012-01-13-normal-magic-squares.html</id>
    <description>An integer programming formulation of the normal magic squares problem.</description>
    <content type="html"><![CDATA[

<p>As a followup to yesterday's post, I created <a href="http://code.google.com/p/python-zibopt/source/browse/trunk/examples/normal-magic-square.py">another python-zibopt example</a> for finding <a href="2012-01-12-magic-squares-and-big-Ms.html">Normal Magic Squares</a>.  This is similar to <a href="http://code.google.com/p/python-zibopt/source/browse/trunk/examples/sudoku.py">the Sudoku example</a>, except that here the number of binary variables depends on the square size.  In the case of Sudoku, each cell has 9 binary variables -- one for each potential value it might take.  For a normal magic square, there are $n^2$ possible values for each cell, $n^2$ cells, and one variable representing the row, column, and diagonal sums.  This makes a total of $n^4$ binary variables and one continuous variables in the model.</p>

<p>However ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Magic Squares and Big-Ms</title>
    <link href="http://ryanjoneil.github.io/posts/2012-01-12-magic-squares-and-big-Ms.html"/>
    <updated>2012-01-12T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2012-01-12-magic-squares-and-big-Ms.html</id>
    <description>An integer programming formulation of the magic squares problem.</description>
    <content type="html"><![CDATA[

<p>When I visited the LA PyLadies <a href="http://www.meetup.com/la-pyladies/events/34789522/">back in October</a> of 2011, I started toying with a model for finding <a href="http://en.wikipedia.org/wiki/Magic_square">Magic Squares</a> in python-zibopt.  As a modeling exercise, this is fun but not too terribly challenging.  Construct a square matrix of integer-valued variables and add the following constraints:</p>

<ol>
<li>All variables &gt;= 1.</li>
<li>All rows, columns, and the diagonal sum to the same value.</li>
<li>All variables take different values.</li>
</ol>

<p><i>Admittedly, I had <a href="http://code.google.com/p/python-zibopt/wiki/ChangeLog#0.7.2_dev">a few bugs</a> to fix in the code before I could get this working.  If you'd like to run it yourself, the model is <a href="http://code.google.com/p/python-zibopt/source/browse/trunk/examples/magic-square.py">here</a>.  It works against the latest ...</i></p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Know Your Time Complexities - Part 2</title>
    <link href="http://ryanjoneil.github.io/posts/2011-11-03-know-your-time-complexities-part-2.html"/>
    <updated>2011-11-03T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-11-03-know-your-time-complexities-part-2.html</id>
    <description>More on the importance of time complexity to basic programming.</description>
    <content type="html"><![CDATA[

<p>In response to <a href="2011-10-25-know-your-time-complexities.html">this</a> post, <a href="http://www.indopedia.org/index.php?title=Ben_Bitdiddle">Ben Bitdiddle</a> inquires:</p>

<blockquote>"I understand the concept of using a companion set to remove duplicates from a list while preserving the order of its elements.  But what should I do if these elements are composed of smaller pieces?  For instance, say I am generating <a href="http://en.wikipedia.org/wiki/Combination">combinations</a> of numbers in which order is unimportant.  How do I make a set recognize that [1,2,3] is the same as [3,2,1] in this case?"</blockquote>

<p>There are a couple points that should help here:</p>

<ol>
<li>
<p>While lists are unhashable and therefore cannot be put into sets, tuples are ...</p></li></ol>]]></content>
  </entry>
  
  <entry>
    <title type="text">Know Your Time Complexities</title>
    <link href="http://ryanjoneil.github.io/posts/2011-10-25-know-your-time-complexities.html"/>
    <updated>2011-10-25T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-10-25-know-your-time-complexities.html</id>
    <description>The importance of time complexity in basic programming.</description>
    <content type="html"><![CDATA[

<p><i>This is based on a lightning talk I gave at the LA PyLadies <a href="http://www.meetup.com/la-pyladies/events/34789522/">October Hackathon</a>.</i></p>

<p>I'm actually not going to go into anything much resembling algorithmic complexity here.  What I'd like to do is present a common performance anti-pattern that I see from novice programmers about once every year or so.  If I can prevent one person from committing this error, this post will have achieved its goal.  I'd also like to show how an intuitive understanding of time required by operations in relation to the size of data they operate on can be helpful.<br /></p>

<p>Say you ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">A Few Notes on Deterministic vs. Stochastic Simulation</title>
    <link href="http://ryanjoneil.github.io/posts/2011-06-11-a-few-notes-on-deterministic-vs-stochastic-simulation.html"/>
    <updated>2011-06-09T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-06-11-a-few-notes-on-deterministic-vs-stochastic-simulation.html</id>
    <description>Mental meanderings about simulation and how to get stakeholders to understand the importance of randomness.</description>
    <content type="html"><![CDATA[

<p>I find I have to build simulations with increasing frequency in my work and life.  Usually this indicates I'm faced with one of the following situations:</p><ol><li>The need for a quick estimate regarding the quantitative behavior of some situation.</li><li>The desire to verify the result of a computation or assumption.</li><li>A situation which is too complex or random to effectively model or understand.</li></ol><p>Anyone familiar at all with simulation will recognize the last item as the motivating force of the entire field.  Simulation models tend to take over when systems become so complex that understanding them is prohibitive in ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Joy in the Time of the Python futures Module</title>
    <link href="http://ryanjoneil.github.io/posts/2011-05-19-joy-in-the-time-of-the-python-futures-module.html"/>
    <updated>2011-04-27T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-05-19-joy-in-the-time-of-the-python-futures-module.html</id>
    <description>Exploit multicore architectures with ease and the Python futures module!</description>
    <content type="html"><![CDATA[

<p>Starting with a does of realism, it's possible this will turn out like the day when <a href="http://docs.python.org/release/2.5/whatsnew/pep-342.html">coroutines were introduced into Python 2.5</a>.  At the time I was extremely excited.  Upon hearing the news I spent several hours trying to convince developers at my then-employer that the only way we could survive as an organization was to immediately abandon all our existing Java infrastructure, porting it to a new and beautiful world based on finite state machines implemented using Python coroutines.  After a day of hand waving over a proof of concept, we all continued about our lives.  Soon ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Affine Scaling in R</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-27-affine-scaling-in-r.html"/>
    <updated>2011-04-27T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-27-affine-scaling-in-r.html</id>
    <description>Affine scaling for interior point optimization in R.</description>
    <content type="html"><![CDATA[

<p>I recently stumbled across an implementation of the <a href="http://demonstrations.wolfram.com/AffineScalingInteriorPointMethod/">affine scaling</a> <a href="http://en.wikipedia.org/wiki/Interior_point_method">interior point method</a> for solving linear programs that I'd coded up in R once upon a time. I'm posting it here in case anyone else finds it useful. There's not a whole lot of thought given to efficiency or numerical stability, just a demonstration of the basic algorithm. Still, sometimes that's exactly what one wants.</p>

<pre><code class="r">solve.affine <- function(A, rc, x, tolerance=10^-7, R=0.999) {
  # Affine scaling method
  while (T) {
    X_diag <- diag(x)

    # Compute (A * X_diag^2 * A^t)-1 using Cholesky factorization.
    # This is responsible for scaling the original problem matrix.
    q <- A %*% X_diag**2 %*% t(A)
    q_inv <- chol2inv(chol(q))

    # lambda = q * A * X_diag^2 * c
    lambda <- q_inv %*% A %*% X_diag^2 %*% rc

    # c - A^t * lambda is used repeatedly
    foo <- rc - t(A) %*% lambda

    # We converge as s goes to zero
    s <- sqrt(sum((X_diag %*% foo)^2))

    # Compute new x
    x <- (x + R * X_diag^2 %*% foo / s)[,]

    # If s is within our tolerance, stop.
    if (abs(s) < tolerance) break
  }
  x
}</code></pre>

<p>This function accepts a matrix A which contains all technological coefficients for an LP, a vector rc containing its reduced costs, and an initial point x interior to the ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Scheme to Python Compilation</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-20-reformed-japhs-in-python-scheme-to-python-compilation.html"/>
    <updated>2011-04-20T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-20-reformed-japhs-in-python-scheme-to-python-compilation.html</id>
    <description>Scheme to Python compilation.</description>
    <content type="html"><![CDATA[

<p>I believe this is the final JAPH in this series. I actually didn't have the heart to obfuscate it. It starts with a Scheme program that prints 'just another scheme hacker', tokenizes it, parses the token stream, compiles that into Python 3.2, and executes the resulting string. If anybody else wants to obfuscate it, be my guest. Otherwise I'll just let it speak for itself.</p>

<pre><code class="py">import re

def tokenize(input):
    '''Tokenizes an input stream into a list of recognizable tokens'''
    token_res = (
        r'\(',      # open paren -> starts expression
        r'\)',      # close paren -> ends expression
        r'"[^"]*"', # quoted string (don't support ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Turing Machine</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-18-reformed-japhs-in-python-turing-machine.html"/>
    <updated>2011-04-18T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-18-reformed-japhs-in-python-turing-machine.html</id>
    <description>Python obfuscation with a Turing Machine</description>
    <content type="html"><![CDATA[

<p>This JAPH constructs a <a href="http://en.wikipedia.org/wiki/Turing_machine">Turing machine</a> in order to achieve its goal.  The machine accepts any string that ends in '\n' and, to assist in our purposes, allows side effects.  This lets us print the value of the tape as it encounters each character.  While the idea of using lambda functions as side effects in a Turing machine is a little bizarre on many levels, we work with what we have.  And Python is multi-paradigmatic, so what the heck.</p>

<pre><code class="py">import re

def turing(tape, transitions):
    # The tape input comes in as a string.  We approximate an infinite
    # length tape via ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Huffman Coding</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-14-reformed-japhs-in-python-huffman-coding.html"/>
    <updated>2011-04-14T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-14-reformed-japhs-in-python-huffman-coding.html</id>
    <description>Python obfuscation and Huffman Coding.</description>
    <content type="html"><![CDATA[

<p>At this point, tricking python into printing strings via ever more pernicious mechanisms got a little boring.  So I switched to obfuscating fundamental computer science algorithms.  Here's a JAPH that takes in a <a href="http://en.wikipedia.org/wiki/Huffman_coding">Huffman coded</a> version of 'just another python hacker', decodes, and prints it.</p>

<pre><code class="py"># Build coding tree
def build_tree(scheme):
    if scheme.startswith('*'):
        left, scheme = build_tree(scheme[1:])
        right, scheme = build_tree(scheme)
        return (left, right), scheme
    else:
        return scheme[0], scheme[1:]

def decode(tree, encoded):
    ret = ''
    node = tree
    for direction in encoded:
        if direction == '0':
            node = node[0]
        else:
            node = node[1]
        if isinstance(node, str):
            ret ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Rolling Effect</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-11-reformed-japhs-in-python-rolling-effect.html"/>
    <updated>2011-04-11T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-11-reformed-japhs-in-python-rolling-effect.html</id>
    <description>Python obfuscation with a cute visual effect.</description>
    <content type="html"><![CDATA[

<p>Here's a JAPH composed solely for effect.  For each letter in 'just another python hacker' it loops over each the characters  ' abcdefghijklmnopqrstuvwxyz', printing each.  Between characters it pauses for 0.05 seconds, backing up and moving on to the next if it hasn't reached the desired one yet.  This achieves a sort of rolling effect by which the final string laboriously appears on our screen.</p>

<pre><code class="py">import string
import sys
import time

letters = ' ' + string.ascii_lowercase
for l in 'just another python hacker':
    for x in letters:
        print(x, end='')
        sys.stdout.flush()
        time.sleep(0.05)

        if x == l ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - ROT13</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-06-reformed-japhs-in-python-rot13.html"/>
    <updated>2011-04-06T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-06-reformed-japhs-in-python-rot13.html</id>
    <description>Python obfuscation using ROT13 encoding.</description>
    <content type="html"><![CDATA[

<p>No series of JAPHs would be complete without <a href="http://en.wikipedia.org/wiki/ROT13">ROT13</a>.  This is the example through which aspiring Perl programmers learn to use tr and its synonym y.  In Perl the basic ROT13 JAPH starts as:</p>

<pre><code class="perl">$foo = 'whfg nabgure crey unpxre';
$foo =~ y/a-z/n-za-m/;
print $foo;
</code></pre>

<p>Python has nothing quite so elegant in its default namespace.  However, this does give us the opportunity to explore a little used aspect of strings: the translate method.  If we construct a dictionary of ordinals we can accomplish the same thing with a touch more effort.</p>

<pre><code class="py">import string

table = {
    ord(x): ord(y) for x ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Ridiculous Anagram</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-03-reformed-japhs-in-python-ridiculous-anagram.html"/>
    <updated>2011-04-03T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-03-reformed-japhs-in-python-ridiculous-anagram.html</id>
    <description>Python obfuscation using anagrams.</description>
    <content type="html"><![CDATA[

<p>Here's the second in my reformed JAPH series.  It takes an anagram of 'just another python hacker' and converts it prior to printing.  It sorts the anagram by the indices of another string, in order of their associated characters.  This is sort of like a pre-digested <a href="http://en.wikipedia.org/wiki/Schwartzian_transform">Schwartzian transform</a>.</p>

<pre><code class="py">x = 'upjohn tehran hectors katy'
y = '1D0HG6JFO9P5ICKAM87B24NL3E'

print(''.join(x[i] for i in sorted(range(len(x)), key=lambda p: y[p])))
</code></pre>

<p>Obfuscation consists mostly of using silly machinations to construct the string we use to sort the anagram.</p>

<pre><code class="py">print(''.join('''upjohn tehran hectors katy'''[_]for _ in sorted ...</code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Reformed JAPHs in Python - Alphabetic Indexing</title>
    <link href="http://ryanjoneil.github.io/posts/2011-04-01-reformed-japhs-in-python-alphabetic-indexing.html"/>
    <updated>2011-04-01T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-04-01-reformed-japhs-in-python-alphabetic-indexing.html</id>
    <description>Python obfuscation.</description>
    <content type="html"><![CDATA[

<p>Full disclosure: I used to be a Perl programmer. (Hey, <a href="http://drforr.livejournal.com/">Jeff.</a>)</p><p>One day I became disillusioned at the progress of Perl 6 and decided to <a href="http://www.python.org/dev/peps/pep-0020/">import this</a>.  This appears to be a fairly common story for Perl to Python converts.  While I haven't looked back much, there are a number of things I really miss about perl <i>(lower case intentional)</i>.  Among other things, I miss having value types in a dynamic language, magical and ill-advised use of <a href="http://www.foo.be/docs/tpj/issues/vol3_1/tpj0301-0003.html">cryptocontext</a>, and sometimes even <a href="http://perldesignpatterns.com/?PseudoHash">pseudohashes</a> because they were inexcusably weird.  A language that supports so many ideas out of the box enables ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Simulating GDP Growth</title>
    <link href="http://ryanjoneil.github.io/posts/2011-02-23-simulating-gdp-growth.html"/>
    <updated>2011-02-23T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-02-23-simulating-gdp-growth.html</id>
    <description>Writing and interpreting simulations about GDP growth in R.</description>
    <content type="html"><![CDATA[

<p><i>[2011-02-24 This post has been corrected.  Near the end it stated that we could be 95% confident China's GDP would overtake the USA between 2057 and 2059.  It should have stated that we could be 95% confident the mean of that year would be between 2057 and 2059.  Thanks to my overbearing subconscious for pointing this out.]</i></p>

<p>I hope you saw <a href="http://www.washingtonpost.com/wp-srv/special/business/china-growth/">Chinaâ€™s way to the top</a> on the Post's website recently.  It's a very clear presentation of their statement and is certainly worth a look.</p>

<p>So say you're an economist and you actually do need ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Data Fitting Part 2a - Very, Very Simple Linear Regression in R</title>
    <link href="http://ryanjoneil.github.io/posts/2011-02-16-data-fitting-part-2a-very-very-simple-linear-regression-in-r.html"/>
    <updated>2011-02-16T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-02-16-data-fitting-part-2a-very-very-simple-linear-regression-in-r.html</id>
    <description>Predict how much people like cats and dogs based on their ice cream preferences. Also, R.</description>
    <content type="html"><![CDATA[

<p>I thought it might be useful to follow up the <a href="2011-02-15-data-fitting-part-2-very-very-simple-linear-regression-in-python.html">last post</a> with another one showing the same examples in R.</p>

<p>R provides a function called lm, which is similar in spirit to <a href="http://numpy.scipy.org/">numpy</a>'s linalg.lstsq.  As you'll see, lm's interface is a bit more tuned to the concepts of modeling.</p>

<p>We begin by reading in the example CSV into a data frame:</p>

<pre><code class="r">> responses <- read.csv('example_data.csv')

> responses
  respondent vanilla.love strawberry.love chocolate.love
1     Serdar            9               4              9
2        Dan            8               6              4
3  Nathaniel            9               4              8
4     Lauren            3               7              9
5        Jen            6               8              5 ...</-></code></pre>]]></content>
  </entry>
  
  <entry>
    <title type="text">Data Fitting Part 2 - Very, Very Simple Linear Regression in Python</title>
    <link href="http://ryanjoneil.github.io/posts/2011-02-15-data-fitting-part-2-very-very-simple-linear-regression-in-python.html"/>
    <updated>2011-02-15T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2011-02-15-data-fitting-part-2-very-very-simple-linear-regression-in-python.html</id>
    <description>Predict how much people like cats and dogs based on their ice cream preferences. Also, Python and numpy.</description>
    <content type="html"><![CDATA[

<p>This post is based on a memo I sent to some former colleagues at the Post.  I've edited it for use here since it fits well as the second in a series on simple data fitting techniques.  If you're among the many enlightened individuals already using regression analysis, then this post is probably not for you.  If you aren't, then hopefully this provides everything you need to develop rudimentary predictive models that yield surprising levels of accuracy.</p>

<p>For purposes of a simple working example, we have collected six records of input data over three dimensions with the ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Off-the-Cuff Voter Fraud Detection</title>
    <link href="http://ryanjoneil.github.io/posts/2010-11-30-off-the-cuff-voter-fraud-detection.html"/>
    <updated>2010-11-30T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2010-11-30-off-the-cuff-voter-fraud-detection.html</id>
    <description>Using the exponential distribution to interpret votes in a web survey.</description>
    <content type="html"><![CDATA[

<p>Consider this scenario:  You run a contest that accepts votes from the general Internet population.  In order to encourage user engagement, you record any and all votes into a database over several days, storing nothing more than the competitor voted for, when each vote is cast, and a cookie set on the voter's computer along with their apparent IP addresses.  If a voter already has a recorded cookie set they are denied subsequent votes.  This way you can avoid requiring site registration, a huge turnoff for your users.  Simple enough.</p>

<p>
Unfortunately, some of the competitors are wily and attached ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Data Fitting Part 1 - Linear Data Fitting</title>
    <link href="http://ryanjoneil.github.io/posts/2010-11-23-data-fitting-part-1-linear-data-fitting.html"/>
    <updated>2010-11-23T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2010-11-23-data-fitting-part-1-linear-data-fitting.html</id>
    <description>An introduction to data fitting and classification using linear optimization in Python.</description>
    <content type="html"><![CDATA[

<p>Data fitting is one of those tasks that everyone should have at least some exposure to.  Certainly developers and analysts will benefit from a working knowledge of its fundamentals and their implementations.  However, in my own reading I've found it difficult to locate good examples that are simple enough to pick up quickly and come with accompanying source code.</p>

<p>
This article commences an ongoing series introducing basic data fitting techniques.  With any luck they won't be overly complex, while still being useful enough to get the point across with a real example and real data.  We'll start ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Easy Monte Carlo Simulation in Python</title>
    <link href="http://ryanjoneil.github.io/posts/2009-10-08-easy-monty-carlo-simulation-in-python.html"/>
    <updated>2009-10-08T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2009-10-08-easy-monty-carlo-simulation-in-python.html</id>
    <description>A quick introduction to writing and interpreting Monte Carlo simulations in Python.</description>
    <content type="html"><![CDATA[

<p>One of the most useful tools one learns in an Operations Research curriculum is <a href="http://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo Simulation</a>.  Its utility lies in its simplicity: one can learn vital information about nearly any process, be it deterministic or stochastic, without wading through the grunt work of finding an analytical solution.  It can be used for off-the-cuff estimates or as a proper scientific tool.  All one needs to know is how to simulate a given process and its appropriate probability distributions and parameters if that process is stochastic.</p>

<p>Here's how it works:</p>

<ul><li>Construct a simulation that, given input values, returns a value ...</li></ul>]]></content>
  </entry>
  
  <entry>
    <title type="text">On the Beauty of Power Sets</title>
    <link href="http://ryanjoneil.github.io/posts/2009-02-27-on-the-beauty-of-power-sets.html"/>
    <updated>2009-02-27T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2009-02-27-on-the-beauty-of-power-sets.html</id>
    <description>Using power sets in algebraic modeling languages for formulating the Traveling Salesman Problem.</description>
    <content type="html"><![CDATA[

<p>One of the difficulties we encounter in solving the <a href="http://www.tsp.gatech.edu/">Traveling Salesman Problem</a> (TSP) is that, for even a small numer of cities, a complete description of the problem requires a factorial number of constraints.  This is apparent in the standard formulation used to teach the TSP to OR students.  Consider a set of $n$ cities with the distance from city $i$ to city $j$ denoted $d_{ij}$.  We attempt to minimize the total distance of a tour entering and leaving each city exactly once.  $x_{ij} = 1$ if the edge from city $i$ to city $j$ is included in the ...</p>]]></content>
  </entry>
  
  <entry>
    <title type="text">Uncapacitated Lot Sizing Formulation</title>
    <link href="http://ryanjoneil.github.io/posts/2009-02-20-uncapacitated-lot-sizing-formulation.html"/>
    <updated>2009-02-20T00:00:00</updated>
    <id>http://ryanjoneil.github.io/posts/2009-02-20-uncapacitated-lot-sizing-formulation.html</id>
    <description>Formulation and aspects of the Uncapacitated Lot Sizing problem in Integer Programming.</description>
    <content type="html"><![CDATA[

<p>Uncapacitated Lot Sizing (ULS) is a classic <a href="http://en.wikipedia.org/wiki/Operations_research">OR</a> problem that seeks to minimize the cost of satisfying known demand for a product over time.  Demand is subject to varying costs for production, set-up, and storage of the product.  Technically, it is a mixed binary integer linear program -- the key point separating it from the world of <a href="http://en.wikipedia.org/wiki/Linear_programming">linear optimization</a> being that production cannot occur during any period without paying that period's fixed costs for set-up.  Thus it has linear nonnegative variables for production and storage amounts during each period, and a binary variable for each period that determines whether or ...</p>]]></content>
  </entry>
  
</feed>
